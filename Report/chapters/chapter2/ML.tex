
\section{یادگیری ماشین}
در این بخش تنها به مفاهیمی از یادگیری ماشین که برای فهم فصول بعدی لازم هستند اشاره می‌شود. \\
در حالت کلی، برای تعریف الگوریتم یا مدل‌های یادگیری ماشین، فرض می‌شود یک مجموعه داده موجود است که داده‌های آن به صورت دسته‌هایی دوتایی به شکل زیر هستند:
\begin{equation}
    (x_i, \hso y_i) \hst ; \hst y_i = g(x_i) \quad  \forall i : 1 \leq i \leq k
\end{equation}
\myequations{نحوه‌ی بررسی مجموعه داده‌ها در یادگیری ماشین}

که
$k$
نشان‌گر تعداد داده‌های موجود در مجموعه داده است؛
به این معنا که فرض می‌شود بین 
$x$ها
و
$y$ها
رابطه‌ی ریاضی‌ای وجود دارد و هدف از طراحی مدل، کشف همین رابطه است. \\
می‌توان الگوریتم یا مدل‌های یادگیری ماشین را به شکل تابعی به صورت زیر نمایش داد:
\begin{equation}
    \Hat{y}_i = f(x_i, \hso \theta) \hst ; \hst x_i \in \mathbb{R}^m, \hspace{1.2mm} \theta \in \mathbb{R}^n
\end{equation}
\myequations{نمایش ریاضی مدل یادگیری ماشین}
تابع
$f$
دو نوع ورودی دریافت می‌کند، یکی
$x$
که معادل داده‌هایی‌ست که از یک مجموعه داده تعیین شده استخراج می‌شود و دیگری
$\theta$
که مجموعه‌ای از پارامترهایی تنظیم‌پذیر است. در مرحله‌ی آموزش
\fnote{Training phase}
این مدل، سعی می‌شود با هدف کمینه کردن یک تابع هزینه
\fnote{Cost function}،
بهینه‌سازی این پارامترها صورت گیرد تا خروجی الگوریتم به جواب دلخواه نزدیک‌تر شود.
تابع هزینه نیز عمدتا با این نیت تعریف می‌گردد که خروجی آن، ملاک خوبی از رضایت‌بخشی خروجی الگوریتم باشد. به عنوان مثال، اگر در یک مجموعه داده،
$x$
معادل مجموعه‌ای از اعداد در یک سری عددی
و
$y$
معادل عدد بعدی ظاهرشده در این مجموعه اعداد باشد، در هنگام تعریف یک مدل یادگیری ماشین برای پیدا کردن عدد بعدی یک مجموعه با گرفتن اعداد قبلی آن، می‌توان تابع هزینه در هر مرحله از آموزش را به این صورت تعریف کرد:
\begin{equation} \label{eqn:mse}
    \mathcal{L}_f = \frac{1}{k} \sum_{i=1}^{k} (\hat{y}_i - y)^2
\end{equation}
\myequations{تابع خطای میانگین مربعات}
به این نوع تابع هزینه، تابع خطای میانگین مربعات
\fnote{Mean squared error}
گفته می‌شود.
% \newpage

بهینه‌سازی پارامترها در الگوریتم‌های یادگیری ماشین، به طور معمول توسط الگوریتم کاهش گرادیانی
\fnote{Gradient descent}
انجام می‌شود؛ به این معنا که میزان تغییرات پارامترها در زمان، طبق معادلات زیر به تابع هزینه وابسته می‌شود.

\begin{equation}
    \frac{\partial \theta_j(t)}{\partial t} = - \eta \frac{\partial \mathcal{L}_f}{\partial \theta_j}
    = - \eta \sum_i \frac{\partial f \big(x_i, \theta (t)\big)}{\partial \theta_j} \frac{\partial \mathcal{L}_f}{\partial f \big(x_i, \theta(t)\big)}
\end{equation}
\myequations{الگوریتم کاهش گرادیانی}
در معادله‌ی بالا، متغیر
$\eta$
به نرخ یادگیری 
\fnote{Learning rate}
معروف است و میزان تغییرات پارامترها با توجه به گرادیان تابع هزینه را تنظیم می‌کند.


\subsection{
شبکه‌های عصبی بازگشتی
}

\begin{figure}
	\centering
	\includegraphics[scale=0.35]{figures/architecture-rnn.png}
	% To make sure citation doesn't appear in list of figures
	\caption [
	ساختار شبکه‌های عصبی بازگشتی
	]{
	ساختار شبکه‌های عصبی بازگشتی 
	\cite{rnncheat}
	}
	\label{fig:rnnarch}
\end{figure}

شبکه‌های عصبی بازگشتی
\fnote{Recurrent neural networks}
گونه‌ی خاصی از الگوریتم‌های یادگیری ماشین هستند که ساختار کلی آن‌ها در شکل
\ref{fig:rnnarch}
آمده است.
در این‌گونه شبکه‌های عصبی نیز
$x$
ها نشان‌گر داده‌های ورودی از مجموعه داده‌ها و
$y$
ها نشان‌گر خروجی‌های الگوریتم هستند.
پارامترهای تنظیم‌پذیر در واحد‌های آبی‌رنگ که به 
واحد‌های بازگشتی
\fnote{Recurrent block}
معروف هستند قرار می‌گیرند.
نکته‌ی اصلی شبکه‌های عصبی بازگشتی این است که هر واحد بازگشتی، در هنگام انجام محاسبات، از نتایج محاسبات واحد‌های محاسباتی قبل از خود استفاده می‌کند، چراکه در این صورت می‌تواند با کسب آگاهی از خروجی‌های گذشته و ترتیب آن‌ها، خروجی معنی‌داری تولید کند.
این‌گونه الگوریتم‌ها اغلب در یادگیری ویژگی‌های داده‌های ترتیبی
\fnote{Sequential data}
کاربرد دارند؛ به این معنا که نه تنها خود خروجی‌های الگوریتم، بلکه ترتیب آن‌ها هم از اهمیت بالایی برخوردار است.
نت‌های موسیقی را نیز می‌توان به صورت مجموعه‌ای از داده‌های ترتیبی در نظر گرفت، چراکه هر مجموعه‌ای از نت‌های موسیقی، صدایی آهنگین تولید نمی‌کند و ترتیب نت‌های قرار گرفته در یک قطعه‌ی موسیقی نیز برای این‌که توسط گوش انسان به عنوان یک موسیقی حقیقی در نظر گرفته شوند حائز اهمیت است.

\subsubsection{حافظه‌ی طولانی کوتاه-مدت}
حافظه‌ی طولانی کوتاه-مدت
\fnote{Long short-term memory}
نوع خاصی از شبکه‌های عصبی بازگشتی است که ساختار کلی  واحد بازگشتی آن در شکل
\ref{fig:lstmblock}
آمده است.
یکی از ویژگی‌های مهمی که حافظه‌های طولانی کوتاه-مدت را در مقایسه با باقی شبکه‌های عصبی بازگشتی متمایز می‌کند، این است که به جای انتقال یک واحد اطلاعات از هر مرحله به مرحله‌ی بعدی، دو واحد اطلاعات را منتقل می‌کند
\cite{lstm_paper}
.

\begin{figure}
	\centering
	\includegraphics[scale=0.4]{figures/lstm-rec-unit.png}
	% To make sure citation doesn't appear in list of figures
	\caption [
	واحد بازگشتی حافظه‌ی طولانی کوتاه-مدت
	]{
	واحد بازگشتی حافظه‌ی طولانی کوتاه-مدت 
	\cite{rnncheat}
	}
	\label{fig:lstmblock}
\end{figure}

گیت‌های بازگشتی، واحدهای پردازشی‌ای هستند که به طور معمول در شبکه‌های عصبی بازگشتی حضور دارند و با علامت 
$\Gamma$
نشان داده می‌شوند. حالت کلی عملیات این گیت‌ها به صورت زیر است:
\begin{equation}
    \Gamma = \sigma(Wx^{(t)} + Ua^{(t-1)} + b)
\end{equation}
\myequations{گیت‌های بازگشتی}
\hsm
که در معادله‌ی بالا، پارامترهای
$W, U, b \hspace{0.5mm}$
همان پارامترهای تنظیم‌پذیر الگوریتم هستند و
$\sigma$
یک تابع غیرخطی است که از آن برای تعمیم توانایی مدل‌سازی شبکه‌های عصبی استفاده می‌شود و معمولا تابع فعال‌سازی
\fnote{Activation function}
نامیده می‌شود.
در حافظه‌های طولانی کوتاه مدت، معمولا از تابع سیگموید
\fnote{Sigmoid function}
به عنوان تابع فعال‌سازی استفاده می‌شود که تعریف این تابع به صورت زیر است:
\begin{equation}
    S(x) = \frac{1}{1+e^{-x}} = \frac{e^x}{e^x + 1}
\end{equation}
\myequations{تابع سیگموید}

همان‌طور که در شکل
\ref{fig:lstmblock}
مشاهده می‌شود، هر واحد بازگشتی حافظه‌های طولانی کوتاه-مدت شامل چهار گیت بازگشتی است که هر کدام به منظور خاصی تعبیه شده‌اند و سعی در پیاده‌سازی رفتار خاصی را دارند:

\begin{itemize}
    \item
    گیت به‌روزرسانی
    \fnote{Update gate}
    یا 
    $\Gamma_u$
    میزان حفظ اطلاعات مراحل گذشته در محاسبات فعلی را تعیین می‌کند.
    
    \item
    گیت ارتباط
    \fnote{Relevance gate}
    یا 
    $\Gamma_r$
    میزان پاک‌شدن اطلاعات مراحل گذشته در محاسبات فعلی را تعیین می‌کند.
    
    \item
    گیت خروجی
    \fnote{Output gate}
    یا 
    $\Gamma_o$
    که میزان حفظ شدن اطلاعات محاسبات فعلی برای انتقال به مرحله‌ی بعدی را تعیین می‌کند.
    
    \item
    گیت فراموشی
    \fnote{Forget gate}
    یا
    $\Gamma_f$
    میزان پاک‌شدن اطلاعات محاسبات فعلی برای انتقال به مرحله‌ی بعدی را تعیین می‌کند.
\end{itemize}

شایان ذکر است که پارامترهای این گیت‌های بازگشتی، معمولا پارامترهای مستقلی هستند و لذا به صورت جداگانه نیز بهینه‌سازی می‌شوند.

در نهایت، خروجی‌های واحد
$t$
-ام یک
حافظه‌ی طولانی کوتاه مدت که با
$c^{(t)}$
و
$a^{(t)}$
نشان داده می‌شوند،
به صورت زیر محاسبه می‌شوند:
\begin{equation}
\begin{gathered}
    \hat{c}^{(t)} = tanh(W_c[\Gamma_r * a^{(t-1)}, x^{(t)}] + b_c) \\
    c^{(t)} = \Gamma_u * \hat{c}^{(t)} + \Gamma_f * c^{(t-1)} \\
    a^{(t)} = \Gamma_o * c^{(t)}
\end{gathered}
\end{equation}
\myequations{خروجی‌های واحد بازگشتی حافظه‌ی طولانی کوتاه-مدت}

\newpage

\subsection{
شبکه‌های زایای دشمن‌گونه
}
هر شبکه‌ی زایای دشمن گونه
\fnote{Generative adversarial network}
، متشکل از دو مدل یادگیری ماشین است
\cite{goodfellow_gan}
.
در هنگام مراحل یادگیری، این دو مدل با یک‌دیگر رقابت می‌کنند و سعی می‌کنند دیگری را در یک بازی مجموع-صفر
\fnote{Zero-sum game}
شکست دهند. یکی از این مدل‌ها، مدل زایا
\fnote{Generative model}
و مدل دیگر، مدل متمایزکننده
\fnote{Discriminative model}
نام دارد. 
با فرض این‌که مجموعه داده‌ای با توزیع مشخصی
مشخص موجود باشد، مدل زایا سعی می‌کند داده‌های جدیدی تولید کند که شباهت زیادی به داده‌های توزیع واقعی داشته باشند. در عین حال، مدل متمایزکننده سعی می‌کند پس از گرفتن یک داده‌ی ورودی، تشخیص دهد که این داده متعلق به آن توزیع است یا خیر.
\\
برای واضح‌تر شدن چگونگی کارکرد شبکه‌های زایای دشمن‌گونه، می‌توان به مساله‌ی تولید پرتره اشاره کرد؛ به این معنا که مجموعه داده‌ای از عکس‌های پرتره‌ی صورت انسان‌های متفاوتی موجود است. در این حالت، مدل زایا تلاش می‌کند تا عکس پرتره‌ی جدیدی تولید کند و مدل متمایزکننده با گرفتن ورودی‌ای، سعی می‌کند تشخیص دهد که این ورودی توسط مدل زایا تولید شده یا از مجموعه داده‌ی اصلی نمونه‌برداری شده است.
در نهایت، در صورت موفق بودن تمرین این دو مدل، مدل زایا می‌تواند عکس‌های پرتره‌ی جدیدی تولید کند که کامپیوتری بودن آن‌ها حتی توسط خود انسان‌ها هم ممکن نباشد و مدل متمایزکننده می‌تواند عکس‌های کامپیوتری را از عکس‌های واقعی به خوبی تشخیص دهد. 
% \end{equation}

\begin{figure}
	\centering
	\includegraphics[scale=0.2]{figures/fakeperson.jpg}
	% To make sure citation doesn't appear in list of figures
	\caption [
	نمونه عکس پرتره‌ی تولید شده توسط شبکه‌ی زایای دشمن‌گونه
	]{
	نمونه عکس پرتره‌ی تولید شده توسط شبکه‌ی زایای دشمن‌گونه
	\cite{thisperson}
	}
	\label{fig:lstmblock}
\end{figure}