{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of main_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "interpreter": {
      "hash": "d2c77ea8d338d5dbf262d683b98c2873f87d453475070b582f093a0c2749b897"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMjfp2zgYszr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a3be82-df6f-482f-de66-60af6d4f7f57"
      },
      "source": [
        "!pip install git+https://github.com/PennyLaneAI/pennylane"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PennyLaneAI/pennylane\n",
            "  Cloning https://github.com/PennyLaneAI/pennylane to /tmp/pip-req-build-x9026cg0\n",
            "  Running command git clone -q https://github.com/PennyLaneAI/pennylane /tmp/pip-req-build-x9026cg0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (2.6.3)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.4.4)\n",
            "Requirement already satisfied: semantic_version==2.6 in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (2.6.0)\n",
            "Requirement already satisfied: autoray in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (0.2.5)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (4.2.4)\n",
            "Requirement already satisfied: pennylane-lightning>=0.18 in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (0.18.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->PennyLane==0.19.0.dev0) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z70RfQb52cPX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch import tensor\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.templates import embeddings as emb\n",
        "from pennylane.templates import layers as lay\n",
        "\n",
        "from typing import Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "import glob, pickle, time"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y11nHDFJ79-C",
        "outputId": "e35a628b-a666-4b55-bb8d-7f24c1b584bc"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKEIMOeK4VQV",
        "outputId": "11c4bc54-dff0-4cf4-b34b-2f80814577a5"
      },
      "source": [
        "!wget https://github.com/theerfan/Maqenta/raw/main/data/notes.pk"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-06 19:20:43--  https://github.com/theerfan/Maqenta/raw/main/data/notes.pk\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/theerfan/Maqenta/main/data/notes.pk [following]\n",
            "--2021-10-06 19:20:43--  https://raw.githubusercontent.com/theerfan/Maqenta/main/data/notes.pk\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 250124 (244K) [application/octet-stream]\n",
            "Saving to: ‘notes.pk.1’\n",
            "\n",
            "\rnotes.pk.1            0%[                    ]       0  --.-KB/s               \rnotes.pk.1          100%[===================>] 244.26K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-10-06 19:20:43 (55.8 MB/s) - ‘notes.pk.1’ saved [250124/250124]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyTkc6uS2cPb"
      },
      "source": [
        "# Midi.py\n",
        "\n",
        "notes_dir = \"notes.pk\"\n",
        "\n",
        "\n",
        "class Midi:\n",
        "    def __init__(self, seq_length, device):\n",
        "        self.seq_length = seq_length\n",
        "        self.device = device\n",
        "\n",
        "        if Path(notes_dir).is_file():\n",
        "            self.notes = pickle.load(open(notes_dir, \"rb\"))\n",
        "            # self.notes = pickle.loads(uploaded[notes_dir])\n",
        "        else:\n",
        "            self.notes = self.get_notes()\n",
        "            pickle.dump(self.notes, open(notes_dir, \"wb\"))\n",
        "\n",
        "        self.network_input, self.network_output = self.prepare_sequences(self.notes)\n",
        "        print(f\"Input shape: {self.network_input.shape}\")\n",
        "        print(f\"Output shape: {self.network_output.shape}\")\n",
        "\n",
        "    def get_notes(self):\n",
        "        \"\"\"Get all the notes and chords from the midi files in the ./midi_songs directory\"\"\"\n",
        "        # This is assuming that every interval between notes is the same (0.5)\n",
        "        notes = []\n",
        "\n",
        "        for file in glob.glob(\"midi_songs/*.mid\"):\n",
        "            midi = converter.parse(file)\n",
        "\n",
        "            print(\"Parsing %s\" % file)\n",
        "\n",
        "            notes_to_parse = None\n",
        "\n",
        "            try:  # file has instrument parts\n",
        "                s2 = instrument.partitionByInstrument(midi)\n",
        "                notes_to_parse = s2.parts[0].recurse()\n",
        "            except:  # file has notes in a flat structure\n",
        "                notes_to_parse = midi.flat.notes\n",
        "\n",
        "            for element in notes_to_parse:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "        with open(notes_dir, \"wb\") as filepath:\n",
        "            pickle.dump(notes, filepath)\n",
        "\n",
        "        return notes\n",
        "\n",
        "    def prepare_sequences(self, notes):\n",
        "        \"\"\"Prepare the sequences used by the Neural Network\"\"\"\n",
        "        self.n_vocab = len(set(notes))\n",
        "\n",
        "        # get all pitch names\n",
        "        pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "        # create a dictionary to map pitches to integers\n",
        "        self.note_to_int = {note: number for number, note in enumerate(pitchnames)}\n",
        "        self.int_to_note = {number: note for number, note in enumerate(pitchnames)}\n",
        "\n",
        "        network_input = []\n",
        "        network_output = []\n",
        "\n",
        "        # create input sequences and the corresponding outputs\n",
        "        for i in range(len(self.notes) - self.seq_length):\n",
        "            sequence_in = self.notes[i : i + self.seq_length]\n",
        "            sequence_out = self.notes[i + self.seq_length]\n",
        "            network_input.append([self.note_to_int[char] for char in sequence_in])\n",
        "            network_output.append(self.note_to_int[sequence_out])\n",
        "\n",
        "        n_patterns = len(network_input)\n",
        "\n",
        "        # reshape the input into a format compatible with LSTM layers\n",
        "        # So this is actuallyt (number of different inputs, sequence length, number of features)\n",
        "        network_input = np.reshape(network_input, (n_patterns, self.seq_length))\n",
        "        network_input = torch.tensor(network_input, device=self.device, dtype=torch.double)\n",
        "\n",
        "        self.input_norms = torch.tensor(torch.linalg.norm(network_input, axis=1))\n",
        "        \n",
        "        # print(network_input.shape)\n",
        "        for i in range(network_input.shape[0]):\n",
        "            network_input[i] /= self.input_norms[i]\n",
        "        # network_input = torch.div(network_input, self.input_norms)\n",
        "\n",
        "        return (\n",
        "            network_input,\n",
        "            torch.tensor(network_output, device=self.device),\n",
        "        )\n",
        "\n",
        "    def create_midi_from_model(self, prediction_output, filename):\n",
        "        \"\"\"convert the output from the prediction to notes and create a midi file\n",
        "        from the notes\"\"\"\n",
        "        offset = 0\n",
        "        output_notes = []\n",
        "\n",
        "        # create note and chord objects based on the values generated by the model\n",
        "        for pattern in prediction_output:\n",
        "            # pattern is a chord\n",
        "            if (\".\" in pattern) or pattern.isdigit():\n",
        "                notes_in_chord = pattern.split(\".\")\n",
        "                notes = []\n",
        "                for current_note in notes_in_chord:\n",
        "                    new_note = note.Note(int(current_note))\n",
        "                    new_note.storedInstrument = instrument.Piano()\n",
        "                    notes.append(new_note)\n",
        "                new_chord = chord.Chord(notes)\n",
        "                new_chord.offset = offset\n",
        "                output_notes.append(new_chord)\n",
        "            # pattern is a note\n",
        "            else:\n",
        "                new_note = note.Note(pattern)\n",
        "                new_note.offset = offset\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                output_notes.append(new_note)\n",
        "\n",
        "            # increase offset each iteration so that notes do not stack\n",
        "            offset += 0.5\n",
        "\n",
        "        midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "        midi_stream.write(\"midi\", fp=filename)\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIMMZq2j2cPh"
      },
      "source": [
        "# QLSTM.py\n",
        "\n",
        "Embedding = Union[emb.AngleEmbedding, emb.AmplitudeEmbedding, emb.BasisEmbedding]\n",
        "Layer = Union[\n",
        "    lay.BasicEntanglerLayers,\n",
        "    lay.ParticleConservingU1,\n",
        "    lay.ParticleConservingU2,\n",
        "    lay.RandomLayers,\n",
        "    lay.StronglyEntanglingLayers,\n",
        "]\n",
        "\n",
        "\n",
        "class QLSTMCell(nn.Module):\n",
        "    def quantum_op(\n",
        "        self,\n",
        "        wires,\n",
        "        embedding: Embedding = emb.AmplitudeEmbedding,\n",
        "        layer: Layer = lay.RandomLayers,\n",
        "    ):\n",
        "        def circuit_part(inputs, weights):\n",
        "            if embedding == emb.AmplitudeEmbedding:\n",
        "              embedding(inputs, wires=wires, normalize=True)\n",
        "            else:\n",
        "              embedding(inputs, wires=wires)\n",
        "            if layer == lay.RandomLayers:\n",
        "              seed = np.random.randint(1, 2**12)\n",
        "              layer(weights, wires=wires, seed=seed)\n",
        "            else:\n",
        "              layer(weights, wires=wires)\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in wires]\n",
        "\n",
        "        return circuit_part\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size,\n",
        "        hidden_size,\n",
        "        n_qubits=4,\n",
        "        n_qlayers=1,\n",
        "        dropout=0,\n",
        "        batch_first=True,\n",
        "        return_sequences=False,\n",
        "        return_state=True,\n",
        "        backend=\"default.qubit\",\n",
        "        device=\"cpu\"\n",
        "    ):\n",
        "        super(QLSTMCell, self).__init__()\n",
        "        self.n_inputs = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.concat_size = self.n_inputs + self.hidden_size\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_qlayers = n_qlayers\n",
        "        self.backend = backend  # \"default.qubit\", \"qiskit.basicaer\", \"qiskit.ibm\"\n",
        "        self.device = device # \"cpu\", \"cuda\"\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.batch_first = batch_first\n",
        "        self.return_sequences = return_sequences\n",
        "        self.return_state = return_state\n",
        "\n",
        "        self.wires_forget = [f\"wire_forget_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_input = [f\"wire_input_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_update = [f\"wire_update_{i}\" for i in range(self.n_qubits)]\n",
        "        self.wires_output = [f\"wire_output_{i}\" for i in range(self.n_qubits)]\n",
        "\n",
        "        self.dev_forget = qml.device(self.backend, wires=self.wires_forget)\n",
        "        self.dev_input = qml.device(self.backend, wires=self.wires_input)\n",
        "        self.dev_update = qml.device(self.backend, wires=self.wires_update)\n",
        "        self.dev_output = qml.device(self.backend, wires=self.wires_output)\n",
        "\n",
        "        self.qlayer_forget = qml.QNode(\n",
        "            self.quantum_op(self.wires_forget), self.dev_forget, interface=\"torch\"\n",
        "        )\n",
        "\n",
        "        self.qlayer_input = qml.QNode(\n",
        "            self.quantum_op(self.wires_input), self.dev_input, interface=\"torch\"\n",
        "        )\n",
        "\n",
        "        self.qlayer_update = qml.QNode(\n",
        "            self.quantum_op(self.wires_update), self.dev_update, interface=\"torch\"\n",
        "        )\n",
        "\n",
        "        self.qlayer_output = qml.QNode(\n",
        "            self.quantum_op(self.wires_output), self.dev_output, interface=\"torch\"\n",
        "        )\n",
        "\n",
        "        weight_shapes = {\"weights\": (n_qlayers, n_qubits)}\n",
        "        print(f\"weight_shapes = (n_qlayers, n_qubits) = ({n_qlayers}, {n_qubits})\")\n",
        "\n",
        "        # self.clayer_in = torch.nn.Linear(self.concat_size, n_qubits)\n",
        "        self.VQC_forget = qml.qnn.TorchLayer(self.qlayer_forget, weight_shapes).to(device)\n",
        "        self.VQC_input = qml.qnn.TorchLayer(self.qlayer_input, weight_shapes).to(device)\n",
        "        self.VQC_update = qml.qnn.TorchLayer(self.qlayer_update, weight_shapes).to(device)\n",
        "        self.VQC_output = qml.qnn.TorchLayer(self.qlayer_output, weight_shapes).to(device)\n",
        "\n",
        "        # self.VQC = {\n",
        "        #     \"forget\": qml.qnn.TorchLayer(self.qlayer_forget, weight_shapes).to(device),\n",
        "        #     \"input\": qml.qnn.TorchLayer(self.qlayer_input, weight_shapes).to(device),\n",
        "        #     \"update\": qml.qnn.TorchLayer(self.qlayer_update, weight_shapes).to(device),\n",
        "        #     \"output\": qml.qnn.TorchLayer(self.qlayer_output, weight_shapes).to(device),\n",
        "        # }\n",
        "        # self.clayer_out = torch.nn.Linear(self.n_qubits, self.hidden_size)\n",
        "\n",
        "        # Turn off classical parameters to see if they're the problem\n",
        "        # for out_param in self.clayer_out.parameters():\n",
        "        #   out_param.requires_grad = False\n",
        "        # for in_param in self.clayer_in.parameters():\n",
        "        #   in_param.requires_grad = False\n",
        "\n",
        "\n",
        "    def forward(self, x, init_states=None):\n",
        "        \"\"\"\n",
        "        x.shape is (batch_size, seq_length, feature_size)\n",
        "        recurrent_activation -> sigmoid\n",
        "        activation -> tanh\n",
        "        \"\"\"\n",
        "        # Automatically assumes single batch\n",
        "        x = x.to(self.device)\n",
        "        # if len(x.shape) == 2:\n",
        "            # x = x.reshape(1, x.shape[0], x.shape[1])\n",
        "        seq_length = x.size()\n",
        "        \n",
        "        # if self.batch_first is True:\n",
        "            # batch_size, seq_length, features_size = x.size()\n",
        "        # else:\n",
        "            # seq_length, batch_size, features_size = x.size()\n",
        "\n",
        "        hidden_seq = []\n",
        "        if init_states is None:\n",
        "            h_t = torch.zeros(self.hidden_size, device=self.device) # hidden state (output)\n",
        "            c_t = torch.zeros(self.hidden_size, device=self.device) # cell state\n",
        "        else:\n",
        "            # for now we ignore the fact that in PyTorch you can stack multiple RNNs\n",
        "            # so we take only the first elements of the init_states tuple init_states[0][0], init_states[1][0]\n",
        "            h_t, c_t = init_states\n",
        "            # h_t = h_t[0]\n",
        "            # c_t = c_t[0]\n",
        "\n",
        "        # for t in range(seq_length):\n",
        "            # get features from the t-th element in seq, for all entries in the batch\n",
        "            # x_t = x[:, t, :]\n",
        "\n",
        "            # Concatenate input and hidden state\n",
        "        y_t = torch.cat((h_t, x), dim=0).float().to(device)\n",
        "\n",
        "        # match qubit dimension\n",
        "        # y_t = self.clayer_in(v_t).to(self.device)\n",
        "        \n",
        "        f_t = torch.sigmoid(self.VQC_forget(y_t).to(self.device))  # forget block\n",
        "        i_t = torch.sigmoid(self.VQC_input(y_t).to(self.device)) # input block\n",
        "        g_t = torch.tanh(self.VQC_update(y_t).to(self.device))  # update block\n",
        "        o_t = torch.sigmoid(self.VQC_output(y_t).to(self.device))\n",
        "        # ).to(self.device)  # output block\n",
        "\n",
        "        c_t = (f_t * c_t) + (i_t * g_t)\n",
        "        h_t = o_t * torch.tanh(c_t)\n",
        "\n",
        "        hidden_seq.append(h_t.unsqueeze(0))\n",
        "\n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "        hidden_seq = hidden_seq.transpose(0, 1).contiguous()\n",
        "\n",
        "        h_t, c_t = h_t.float(), c_t.float()\n",
        "\n",
        "        if self.dropout:\n",
        "          F.dropout(h_t, self.dropout, inplace=True)\n",
        "\n",
        "        if self.return_state:\n",
        "            if self.return_sequences:\n",
        "                return hidden_seq, (h_t, c_t)\n",
        "            else:\n",
        "                return (h_t, c_t)\n",
        "        else:\n",
        "            if self.return_sequences:\n",
        "                return hidden_seq\n",
        "            else:\n",
        "                return h_t\n",
        "    \n",
        "    def predict(self, x, init_states=None):\n",
        "        return self.forward(x, init_states)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE5yYIB3XKu3"
      },
      "source": [
        "class QLSTM(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size: int, hidden_size: int, n_layers: int, n_qubits: list, n_qlayers: list, dropouts: list, backend=\"default.qubit\", device=\"cpu\"):\n",
        "    super(QLSTM, self).__init__()\n",
        "    self.models = nn.ModuleList()\n",
        "    self.n_layers = n_layers\n",
        "    for i in range(self.n_layers):\n",
        "      self.models.append(\n",
        "          QLSTMCell(input_size, hidden_size, n_qubits[i], n_qlayers[i], dropouts[i], backend=backend, device=device)\n",
        "      )\n",
        "    \n",
        "  def forward(self, note_sequences):\n",
        "    # A tuple of (h_t, c_t)\n",
        "    outputs = []\n",
        "    h_t_c_t = None\n",
        "    for i in range(self.n_layers):\n",
        "      h_t_c_t = self.models[i](note_sequences[i], h_t_c_t)\n",
        "      # Only output c_t\n",
        "      outputs.append(h_t_c_t[1])\n",
        "    \n",
        "    # print(outputs)\n",
        "    return torch.stack(outputs)\n",
        "\n",
        "  def predict(self, note_sequences):\n",
        "    return self.forward(note_sequences)\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg9XF7zHCKZe"
      },
      "source": [
        "def post_processing(ct_list, starting_i):\n",
        "  for j in range(starting_i, starting_i + ct_list.shape[0]):\n",
        "    ct_list[j] = (ct_list[j] * float(midi.input_norms[j])).long()\n",
        "  return ct_list"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AgEdPUc2cPk"
      },
      "source": [
        "# LSTMusic.py\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch import optim\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# from QLTSM.qlstm import QLSTM\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LSTMusic(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_qlayers=1,\n",
        "        n_layers=1,\n",
        "        dropout=0.3,\n",
        "        n_vocab=None,\n",
        "        input_dim=1,\n",
        "        hidden_dim=512,\n",
        "        n_qubits=4,\n",
        "        backend=\"default.qubit\",\n",
        "        device=\"cpu\",\n",
        "    ):\n",
        "        super(LSTMusic, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        if n_qubits > 0:\n",
        "            print(f\"Generator will use Quantum LSTM running on backend {backend}\")\n",
        "            r_n = range(n_layers)\n",
        "            n_qubits = [n_qubits for _ in r_n]\n",
        "            n_qlayers = [n_qlayers for _ in r_n]\n",
        "            dropouts = [dropout for _ in r_n]\n",
        "            self.model = QLSTM(input_dim, hidden_dim, n_layers, n_qubits, n_qlayers, dropouts, device=device).to(device)\n",
        "        else:\n",
        "            print(\"Generator will use Classical LSTM\")\n",
        "            self.model = nn.LSTM(input_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "\n",
        "    def forward(self, note_sequences):\n",
        "        ct_list = self.model(note_sequences)\n",
        "        return torch.abs(ct_list)\n",
        "        # scores = []\n",
        "        # for c_t in ct_list:\n",
        "          # scores.append(F.log_softmax(c_t, dim=1))\n",
        "        # ct_list = torch.stack(scores)\n",
        "        # return ct_list.reshape(ct_list.shape[0], ct_list.shape[2])\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        mode=True,\n",
        "        inputs=None,\n",
        "        outputs=None,\n",
        "        n_epochs=None,\n",
        "        cutoff: int = None,\n",
        "        learning_rate=0.1,\n",
        "    ):\n",
        "        # Same as categorical cross entropy, who would've thought?!\n",
        "        if mode == False:\n",
        "            return\n",
        "        loss_function = nn.NLLLoss()\n",
        "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, self.model.parameters()), lr=learning_rate)\n",
        "\n",
        "        if cutoff:\n",
        "            inputs = inputs[:cutoff]\n",
        "            outputs = outputs[:cutoff]\n",
        "\n",
        "        history = {\"loss\": []}\n",
        "\n",
        "        midi_data = list(zip(inputs, outputs))\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            counter = 0\n",
        "            losses = []\n",
        "\n",
        "            for i in range(0, len(midi_data) - self.n_layers, self.n_layers):\n",
        "              data = midi_data[i:i+self.n_layers]\n",
        "              note_seqs = [datum[0] for datum in data]\n",
        "              next_notes = torch.stack([datum[1] for datum in data])\n",
        "              optimizer.zero_grad()\n",
        "              c_t_list = self(note_seqs)\n",
        "              # c_t_list = c_t_list.reshape(c_t_list.shape[0], c_t_list.shape[2])\n",
        "              # print(c_t_list.shape, next_notes.reshape(self.n_layers).shape)\n",
        "              loss = loss_function(c_t_list, next_notes.reshape(self.n_layers).long())\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              losses.append(float(loss))\n",
        "\n",
        "\n",
        "\n",
        "              # print_parameters()\n",
        "\n",
        "              if counter % 5 == 0:\n",
        "                print(f\"On datapoint #{counter} out of {cutoff}\")\n",
        "              counter += 1\n",
        "\n",
        "            avg_loss = np.mean(losses)\n",
        "            history[\"loss\"].append(avg_loss)\n",
        "            print(\"Epoch {} / {}: Loss = {:.3f}\".format(epoch + 1, n_epochs, avg_loss))\n",
        "        return history"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0r6iXZ82cPm"
      },
      "source": [
        "n_qubits = 6\n",
        "seq_length = 2**n_qubits - n_qubits\n",
        "n_epochs = 1\n",
        "cutoff = 200\n",
        "n_layers = 4\n",
        "n_qlayers = 2\n",
        "\n",
        "model_name = f\"lstm{n_layers}-seq{seq_length}-cut{cutoff}-epcs{n_epochs}-qu{n_qubits}-nq{n_qlayers}\"\n",
        "model_str = f\"{model_name}.pt\""
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a33Nq6eh2cPm",
        "outputId": "52e5f342-1155-4083-9570-43e8fa153883"
      },
      "source": [
        "print(\"Initialized Midi\")\n",
        "midi = Midi(seq_length, device)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Midi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([44798, 58])\n",
            "Output shape: torch.Size([44798])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LafpbTRVYeE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097397a9-0323-4a38-98e7-230238e4c5ba"
      },
      "source": [
        "print(\"Initialized LSTM\")\n",
        "lstm = LSTMusic(n_qubits=n_qubits, n_qlayers=n_qlayers, n_layers=n_layers, hidden_dim=n_qubits, device=device).to(device)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized LSTM\n",
            "Generator will use Quantum LSTM running on backend default.qubit\n",
            "weight_shapes = (n_qlayers, n_qubits) = (2, 5)\n",
            "weight_shapes = (n_qlayers, n_qubits) = (2, 5)\n",
            "weight_shapes = (n_qlayers, n_qubits) = (2, 5)\n",
            "weight_shapes = (n_qlayers, n_qubits) = (2, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWXB84ccy4kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc3d330-8d61-4856-a5bd-d9c14172c380"
      },
      "source": [
        "# for param in lstm.model.models[0].clayer_in.parameters():\n",
        "#   print(param.requires_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sJM8dALYjfE"
      },
      "source": [
        "def print_parameters():\n",
        "  for name, param in lstm.named_parameters():\n",
        "      if param.requires_grad:\n",
        "          print(name, param.data)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "-rkZC4Yb2cPn",
        "outputId": "4fc43930-1f1f-43e8-be92-84b8601e9067"
      },
      "source": [
        "# TODO: Separate input data to test/train\n",
        "\n",
        "if Path(model_str).is_file():\n",
        "    print(\"Loading model\")\n",
        "    lstm.load_state_dict(torch.load(model_str))\n",
        "    lstm.eval()\n",
        "    # lstm = torch.load(model_str)\n",
        "else:\n",
        "    print(\"Training LSTM\")\n",
        "    train_history = lstm.train(\n",
        "        True, midi.network_input, midi.network_output, n_epochs=n_epochs, cutoff=cutoff\n",
        "    )\n",
        "    torch.save(lstm.state_dict(), model_str)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LSTM\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-b0d5fa8bd6f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training LSTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     train_history = lstm.train(\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-90b9d90308a0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mode, inputs, outputs, n_epochs, cutoff, learning_rate)\u001b[0m\n\u001b[1;32m     84\u001b[0m               \u001b[0mnext_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m               \u001b[0mc_t_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m               \u001b[0;31m# c_t_list = c_t_list.reshape(c_t_list.shape[0], c_t_list.shape[2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m               \u001b[0;31m# print(c_t_list.shape, next_notes.reshape(self.n_layers).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-90b9d90308a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, note_sequences)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mct_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mct_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# scores = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-35abe6498298>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, note_sequences)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mh_t_c_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mh_t_c_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnote_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t_c_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;31m# Only output c_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_t_c_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-67d5419785ca>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, init_states)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# y_t = self.clayer_in(v_t).to(self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mf_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVQC_forget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# forget block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mi_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVQC_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# input block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVQC_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnn/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnn/torch.py\u001b[0m in \u001b[0;36m_evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         }\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;31m# construct the tape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;31m# If the observable contains a Hamiltonian and the device does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqfunc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqfunc_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-105-67d5419785ca>\u001b[0m in \u001b[0;36mcircuit_part\u001b[0;34m(inputs, weights)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcircuit_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmplitudeEmbedding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m               \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/templates/embeddings/amplitude.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, features, wires, pad_with, normalize, pad, do_queue, id)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_queue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/templates/embeddings/amplitude.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(features, wires, pad_with, normalize)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpad_with\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwires\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             raise ValueError(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;34mf\"Features must be of length {2 ** len(wires)}; got length {n_features}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;34mf\"Use the 'pad' argument for automated padding.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Features must be of length 32; got length 63. Use the 'pad' argument for automated padding."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTxPm8XrDuLa"
      },
      "source": [
        "def generate_notes(self, network_input, int_to_note, n_vocab, n_notes, n_layers):\n",
        "        \"\"\"Generate notes from the neural network based on a sequence of notes\"\"\"\n",
        "        # pick a random sequence from the input as a starting point for the prediction\n",
        "        with torch.no_grad():\n",
        "            req_size = n_notes//n_layers\n",
        "            start = np.random.randint(0, len(network_input) - req_size)\n",
        "\n",
        "            # pattern = network_input[start]\n",
        "            prediction_output = []\n",
        "\n",
        "            # generate n_notes\n",
        "            for i in range(start, start + n_notes, n_layers):\n",
        "                # print(network_input[i:i+n_layers].shape)\n",
        "                prediction_input = network_input[i:i+n_layers]\n",
        "                # prediction_input = pattern.clone().detach().reshape(1, len(pattern), 1)\n",
        "                # prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "                ct_list = self.model.predict(prediction_input)\n",
        "                # print(ct_list)\n",
        "\n",
        "                for prediction in ct_list:\n",
        "                  index = prediction.argmax()\n",
        "                  result = int_to_note[int(index)]\n",
        "                  prediction_output.append(result)\n",
        "\n",
        "                # added_index = (index / n_vocab).reshape(1, 1)\n",
        "                # pattern = torch.cat((pattern, added_index), 0)\n",
        "                # pattern.append(index)\n",
        "                # pattern = pattern[1 : len(pattern)]\n",
        "\n",
        "            return prediction_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_b611mvCNtt"
      },
      "source": [
        "n_notes = 20\n",
        "req_size = n_notes//n_layers\n",
        "start = np.random.randint(0, len(midi.network_input) - req_size)\n",
        "with torch.no_grad():\n",
        "  prediction_input = midi.network_input[start:start+n_layers]\n",
        "  ct_list = lstm.model.predict(prediction_input)\n",
        "  print(ct_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI1_uUzqBw5C"
      },
      "source": [
        "print_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7PVNr3_2cPo"
      },
      "source": [
        "print(\"Generating notes\")\n",
        "notes = generate_notes(\n",
        "    lstm, midi.network_input, midi.int_to_note, midi.n_vocab, n_notes=20, n_layers=n_layers\n",
        ")\n",
        "notes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChgF6LoQ2cPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffbb1f03-51b4-484b-a736-99a9bfad427c"
      },
      "source": [
        "print(\"Saving as MIDI file.\")\n",
        "midi.create_midi_from_model(notes, f\"{model_name}_generated_1.mid\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving as MIDI file.\n"
          ]
        }
      ]
    }
  ]
}