{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuGan-pennyLane-improved.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('venv': venv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "dc44aa18a01d4ef3c49dce97499f9883b1b573f96a33e2e79347f993e3562639"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9NOkxg_pBM_",
        "outputId": "2378b80b-6150-4842-e074-0527239e6ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+https://github.com/PennyLaneAI/pennylane"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PennyLaneAI/pennylane\n",
            "  Cloning https://github.com/PennyLaneAI/pennylane to /tmp/pip-req-build-13rzz5al\n",
            "  Running command git clone -q https://github.com/PennyLaneAI/pennylane /tmp/pip-req-build-13rzz5al\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (2.6.3)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (1.4.4)\n",
            "Collecting semantic_version==2.6\n",
            "  Downloading semantic_version-2.6.0-py3-none-any.whl (14 kB)\n",
            "Collecting autoray\n",
            "  Downloading autoray-0.2.5-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from PennyLane==0.19.0.dev0) (4.2.2)\n",
            "Collecting pennylane-lightning>=0.18\n",
            "  Downloading PennyLane_Lightning-0.18.0-cp37-cp37m-manylinux2010_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd->PennyLane==0.19.0.dev0) (0.16.0)\n",
            "Building wheels for collected packages: PennyLane\n",
            "  Building wheel for PennyLane (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PennyLane: filename=PennyLane-0.19.0.dev0-py3-none-any.whl size=658655 sha256=b7f34fe5a93fc322a11a58af1ce8218c1eef8dea2ae3c2e028e1377ded1712bb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6ud5_2hf/wheels/9e/4b/fe/27dcf8ba174161f9d1af1841251dc97013a33a66f16cd8d661\n",
            "Successfully built PennyLane\n",
            "Installing collected packages: semantic-version, pennylane-lightning, autoray, PennyLane\n",
            "Successfully installed PennyLane-0.19.0.dev0 autoray-0.2.5 pennylane-lightning-0.18.0 semantic-version-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAb_ay37ZFxl"
      },
      "source": [
        "import pennylane as qml\n",
        "\n",
        "from pennylane.templates.layers import BasicEntanglerLayers, StronglyEntanglingLayers, RandomLayers\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding\n",
        "import pennylane.numpy as np\n",
        "import torch\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "\n",
        "from pathlib import Path\n",
        "import pickle, glob "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJArgegTZtVl",
        "outputId": "2ccb5849-4158-4315-dad9-8980d788cf0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_wires = 10\n",
        "wires_range = range(n_wires)\n",
        "\n",
        "n_note_encoding = 6 \n",
        "encoding_range = range(n_note_encoding)\n",
        "\n",
        "dev = qml.device('default.qubit', wires=n_wires)\n",
        "\n",
        "running_dev = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "running_dev"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BztExfRotBp",
        "outputId": "ed11c61e-7087-46f3-8b86-fd41fd9005d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://github.com/theerfan/Maqenta/raw/main/data/notes.pk"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-30 22:42:49--  https://github.com/theerfan/Maqenta/raw/main/data/notes.pk\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/theerfan/Maqenta/main/data/notes.pk [following]\n",
            "--2021-09-30 22:42:50--  https://raw.githubusercontent.com/theerfan/Maqenta/main/data/notes.pk\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 250124 (244K) [application/octet-stream]\n",
            "Saving to: ‘notes.pk’\n",
            "\n",
            "notes.pk            100%[===================>] 244.26K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-30 22:42:50 (2.02 MB/s) - ‘notes.pk’ saved [250124/250124]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYUGm4mUotBs"
      },
      "source": [
        "# Midi.py\n",
        "\n",
        "notes_dir = \"notes.pk\"\n",
        "\n",
        "\n",
        "class Midi:\n",
        "    def __init__(self, seq_length, device):\n",
        "        self.seq_length = seq_length\n",
        "        self.device = device\n",
        "\n",
        "        if Path(notes_dir).is_file():\n",
        "            self.notes = pickle.load(open(notes_dir, \"rb\"))\n",
        "            # self.notes = pickle.loads(uploaded[notes_dir])\n",
        "        else:\n",
        "            self.notes = self.get_notes()\n",
        "            pickle.dump(self.notes, open(notes_dir, \"wb\"))\n",
        "\n",
        "        self.network_input, self.network_output = self.prepare_sequences(self.notes)\n",
        "        print(f\"Input shape: {self.network_input.shape}\")\n",
        "        print(f\"Output shape: {self.network_output.shape}\")\n",
        "\n",
        "    def get_notes(self):\n",
        "        \"\"\"Get all the notes and chords from the midi files in the ./midi_songs directory\"\"\"\n",
        "        # This is assuming that every interval between notes is the same (0.5)\n",
        "        notes = []\n",
        "\n",
        "        for file in glob.glob(\"midi_songs/*.mid\"):\n",
        "            midi = converter.parse(file)\n",
        "\n",
        "            print(\"Parsing %s\" % file)\n",
        "\n",
        "            notes_to_parse = None\n",
        "\n",
        "            try:  # file has instrument parts\n",
        "                s2 = instrument.partitionByInstrument(midi)\n",
        "                notes_to_parse = s2.parts[0].recurse()\n",
        "            except:  # file has notes in a flat structure\n",
        "                notes_to_parse = midi.flat.notes\n",
        "\n",
        "            for element in notes_to_parse:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append(\".\".join(str(n) for n in element.normalOrder))\n",
        "\n",
        "        with open(notes_dir, \"wb\") as filepath:\n",
        "            pickle.dump(notes, filepath)\n",
        "\n",
        "        return notes\n",
        "\n",
        "    def prepare_sequences(self, notes):\n",
        "        \"\"\"Prepare the sequences used by the Neural Network\"\"\"\n",
        "        self.n_vocab = len(set(notes))\n",
        "\n",
        "        # get all pitch names\n",
        "        pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "        # create a dictionary to map pitches to integers\n",
        "        self.note_to_int = {note: number for number, note in enumerate(pitchnames)}\n",
        "        self.int_to_note = {number: note for number, note in enumerate(pitchnames)}\n",
        "\n",
        "        network_input = []\n",
        "        network_output = []\n",
        "\n",
        "        # create input sequences and the corresponding outputs\n",
        "        for i in range(len(self.notes) - self.seq_length):\n",
        "            sequence_in = self.notes[i : i + self.seq_length]\n",
        "            sequence_out = self.notes[i + self.seq_length]\n",
        "            network_input.append([self.note_to_int[char] for char in sequence_in])\n",
        "            network_output.append(self.note_to_int[sequence_out])\n",
        "\n",
        "        n_patterns = len(network_input)\n",
        "\n",
        "        # reshape the input into a format compatible with LSTM layers\n",
        "        # So this is actuallyt (number of different inputs, sequence length, number of features)\n",
        "        network_input = np.reshape(network_input, (n_patterns, self.seq_length))\n",
        "        network_input = torch.tensor(network_input, device=self.device, dtype=torch.double)\n",
        "\n",
        "        self.input_norms = torch.tensor(torch.linalg.norm(network_input, axis=1))\n",
        "        \n",
        "        # print(network_input.shape)\n",
        "        for i in range(network_input.shape[0]):\n",
        "            network_input[i] /= self.input_norms[i]\n",
        "        # network_input = torch.div(network_input, self.input_norms)\n",
        "\n",
        "        return (\n",
        "            network_input,\n",
        "            torch.tensor(network_output, device=self.device),\n",
        "        )\n",
        "\n",
        "    def create_midi_from_model(self, prediction_output, filename):\n",
        "        \"\"\"convert the output from the prediction to notes and create a midi file\n",
        "        from the notes\"\"\"\n",
        "        offset = 0\n",
        "        output_notes = []\n",
        "\n",
        "        # create note and chord objects based on the values generated by the model\n",
        "        for pattern in prediction_output:\n",
        "            # pattern is a chord\n",
        "            if (\".\" in pattern) or pattern.isdigit():\n",
        "                notes_in_chord = pattern.split(\".\")\n",
        "                notes = []\n",
        "                for current_note in notes_in_chord:\n",
        "                    new_note = note.Note(int(current_note))\n",
        "                    new_note.storedInstrument = instrument.Piano()\n",
        "                    notes.append(new_note)\n",
        "                new_chord = chord.Chord(notes)\n",
        "                new_chord.offset = offset\n",
        "                output_notes.append(new_chord)\n",
        "            # pattern is a note\n",
        "            else:\n",
        "                new_note = note.Note(pattern)\n",
        "                new_note.offset = offset\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                output_notes.append(new_note)\n",
        "\n",
        "            # increase offset each iteration so that notes do not stack\n",
        "            offset += 0.5\n",
        "\n",
        "        midi_stream = stream.Stream(output_notes)\n",
        "\n",
        "        midi_stream.write(\"midi\", fp=filename)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgzWrWeDotBw",
        "outputId": "1e49715a-03d4-41f0-d645-c484e8a7eb94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seq_length = 2 **  n_note_encoding\n",
        "print(\"Initialized Midi\")\n",
        "midi = Midi(seq_length, running_dev)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Midi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:79: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([44792, 64])\n",
            "Output shape: torch.Size([44792])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCXwHftJotB0",
        "outputId": "28d81109-d4ba-4ca7-82dd-10ee5bdb6b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "midi.input_norms[120]\n",
        "midi.network_input[120]\n",
        "midi.network_input[120]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1702, 0.0974, 0.1533, 0.0974, 0.0890, 0.1832, 0.0890, 0.1702, 0.0890,\n",
              "        0.1533, 0.0890, 0.1910, 0.0974, 0.1702, 0.0974, 0.1832, 0.0974, 0.1747,\n",
              "        0.0974, 0.1832, 0.0890, 0.1793, 0.0890, 0.1618, 0.0890, 0.0890, 0.1533,\n",
              "        0.0974, 0.0974, 0.0974, 0.0974, 0.0890, 0.0890, 0.0890, 0.0890, 0.0974,\n",
              "        0.0974, 0.0974, 0.0974, 0.1611, 0.0890, 0.1527, 0.0890, 0.1832, 0.0890,\n",
              "        0.0890, 0.1793, 0.0974, 0.0974, 0.0974, 0.0974, 0.0890, 0.0890, 0.0890,\n",
              "        0.0890, 0.0974, 0.0974, 0.0974, 0.0974, 0.1832, 0.0767, 0.1793, 0.1708,\n",
              "        0.1832], device='cuda:0', dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdxqkcOUotB2"
      },
      "source": [
        "def real_music(notes):\n",
        "    AmplitudeEmbedding(features=notes, wires=encoding_range, normalize=True)\n",
        "\n",
        "def music_generator(weights):\n",
        "    # StronglyEntanglingLayers(weights, wires=encoding_range)\n",
        "    # BasicEntanglerLayers(weights, wires=encoding_range)\n",
        "    RandomLayers(weights, wires=encoding_range)\n",
        "\n",
        "def discriminator(weights):\n",
        "    BasicEntanglerLayers(weights, wires=wires_range)\n",
        "    # StronglyEntanglingLayers(weights, wires=wires_range)\n",
        "\n",
        "def measurement(wire_count):\n",
        "    obs = qml.PauliZ(0)\n",
        "    for i in range(1, wire_count):\n",
        "        obs = obs @ qml.PauliZ(i)\n",
        "    return qml.expval(obs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA3oT7fAotB4"
      },
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def real_music_discriminator(inputs, weights):\n",
        "    real_music(inputs)\n",
        "    discriminator(weights)\n",
        "    return measurement(n_note_encoding)\n",
        "\n",
        "def music_generator_circuit(inputs, note_weights):\n",
        "  real_music(inputs)\n",
        "  music_generator(note_weights)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def generated_music_discriminator(inputs, note_weights, weights):\n",
        "    music_generator_circuit(inputs, note_weights)\n",
        "    discriminator(weights)\n",
        "    return measurement(n_note_encoding)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZFDG_HgotB6"
      },
      "source": [
        "n_disc_layers = 8\n",
        "n_gen_layers = 12\n",
        "\n",
        "real_shapes = {\"weights\": (n_disc_layers, n_wires)}\n",
        "\n",
        "real_layer = qml.qnn.TorchLayer(real_music_discriminator, real_shapes).to(running_dev)\n",
        "\n",
        "generated_shapes = {\n",
        "    \"weights\": (n_disc_layers, n_wires),\n",
        "    \"note_weights\": (n_gen_layers, n_note_encoding),\n",
        "}\n",
        "\n",
        "generated_layer = qml.qnn.TorchLayer(generated_music_discriminator, generated_shapes).to(running_dev)\n",
        "generated_layer.weights.requires_grad=False"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G_cIU7HotB8"
      },
      "source": [
        "def sync_weights(source_layer, target_layer):\n",
        "    \"\"\"Synchronize the weights of two layers\"\"\"\n",
        "    source_weights = source_layer.weights\n",
        "    target_weights = target_layer.weights\n",
        "    with torch.no_grad():\n",
        "        for source_weight, target_weight in zip(source_weights, target_weights):\n",
        "            target_weight.data = source_weight.data"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHOALwB2otB9"
      },
      "source": [
        "def prob_fun_disc_true(layer):\n",
        "    def prob_true(inputs):\n",
        "        true_output = layer(inputs)\n",
        "        # Convert to probability\n",
        "        prob_true = (true_output + 1) / 2\n",
        "        return prob_true\n",
        "\n",
        "    return prob_true"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e_tQb8zotB-"
      },
      "source": [
        "prob_real_true = prob_fun_disc_true(real_layer)\n",
        "prob_gen_true = prob_fun_disc_true(generated_layer)\n",
        "\n",
        "empty_input = torch.tensor(np.zeros((1,))).to(running_dev)\n",
        "\n",
        "def disc_cost(inputs):\n",
        "    return prob_gen_true(inputs) - prob_real_true(inputs)\n",
        "\n",
        "def gen_cost(inputs):\n",
        "    return -prob_gen_true(inputs)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBNO6Q3totB_"
      },
      "source": [
        "def gen_batch_inputs(batch_size=1):\n",
        "    return midi.network_input[\n",
        "        np.random.randint(0, len(midi.network_input), size=batch_size)\n",
        "    ]\n",
        "\n",
        "def shuffle_music(datapoint):\n",
        "  return datapoint[torch.randperm(datapoint.size()[0])].detach()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4LqIAqsotCA"
      },
      "source": [
        "def discriminator_iteration(n_iterations, batch_size, learning_rate):\n",
        "\n",
        "    opt = torch.optim.Adam(real_layer.parameters(), lr=learning_rate)\n",
        "    best_cost = disc_cost(midi.network_input[0])\n",
        "    \n",
        "    for _ in range(n_iterations):\n",
        "        opt.zero_grad()\n",
        "        # Sample a batch of data\n",
        "        batch_inputs = gen_batch_inputs()\n",
        "        # batch_inputs = gen_batch_inputs(batch_size)\n",
        "        # batch_inputs = batch_inputs / midi.input_norms[:batch_size]\n",
        "        batch_inputs = batch_inputs.detach()\n",
        "        # Compute the loss\n",
        "        loss = disc_cost(batch_inputs)\n",
        "        # Backpropagate the loss\n",
        "        loss.backward()\n",
        "        # Update the weights\n",
        "        opt.step()\n",
        "        # Update the best cost\n",
        "        if loss < best_cost:\n",
        "            best_cost = loss\n",
        "    print(\"New best Discriminator cost:\", best_cost)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VHdC5YOotCC"
      },
      "source": [
        "def generator_iteration(n_iterations, learning_rate):\n",
        "    opt = torch.optim.SGD(filter(lambda p: p.requires_grad, generated_layer.parameters()), lr=learning_rate)\n",
        "    best_cost = gen_cost(midi.network_input[0])\n",
        "    \n",
        "    for _ in range(n_iterations):\n",
        "        opt.zero_grad()\n",
        "        # Compute the loss\n",
        "\n",
        "        batch_inputs = gen_batch_inputs()\n",
        "        batch_inputs = shuffle_music(batch_inputs)\n",
        "\n",
        "        # print(generated_layer.note_weights)\n",
        "\n",
        "        loss = gen_cost(batch_inputs)\n",
        "        # Backpropagate the loss\n",
        "        loss.backward()\n",
        "        # Update the weights\n",
        "        opt.step()\n",
        "        # Update the best cost\n",
        "        if loss < best_cost:\n",
        "            best_cost = loss\n",
        "    print(\"New best Generator cost:\", best_cost)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGaYsOfgS9iG",
        "outputId": "1399ff40-9cc7-44a8-d7c3-e50d31ad9616",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "generated_layer.note_weights"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[2.5184, 3.6588, 6.0432, 2.9303, 5.1883, 3.3331],\n",
              "        [4.8105, 5.3253, 1.4425, 5.7844, 5.4599, 4.9845],\n",
              "        [2.2610, 6.6459, 5.0264, 1.4935, 4.6006, 1.7620],\n",
              "        [5.2205, 5.9972, 6.5411, 6.1320, 5.1401, 2.2940],\n",
              "        [5.3823, 0.2675, 2.4008, 5.1411, 3.9892, 5.1334],\n",
              "        [2.6419, 2.6896, 5.0165, 2.9585, 1.4269, 3.4058],\n",
              "        [0.0591, 5.3095, 4.7106, 0.6377, 1.4596, 4.8107],\n",
              "        [0.7458, 5.2583, 5.6692, 2.7932, 5.4373, 1.9922],\n",
              "        [0.9095, 6.2672, 2.3002, 4.3995, 5.8379, 4.2808],\n",
              "        [2.6483, 7.9516, 2.8967, 4.0177, 3.1947, 3.8167],\n",
              "        [1.4953, 3.7872, 3.1900, 1.1248, 1.5764, 0.1559],\n",
              "        [3.9383, 4.8912, 5.0823, 4.1093, 3.5412, 4.9737]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a6dvXrjotCC",
        "outputId": "a754ce6a-7923-4bb0-9dda-50dfb3f0dad9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The real iteration\n",
        "steps = 20\n",
        "n_iterations = 10\n",
        "learning_rate = 0.1\n",
        "batch_size = 3\n",
        "\n",
        "for _ in range(steps):\n",
        "    discriminator_iteration(n_iterations, batch_size, learning_rate)\n",
        "    sync_weights(real_layer, generated_layer)\n",
        "    generator_iteration(n_iterations, learning_rate)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best Discriminator cost: tensor(-0.0344, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.4860, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(-0.0296, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.4948, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(-0.0239, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.4972, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(-0.0178, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5020, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(-0.0117, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5129, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(-0.0057, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5142, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0005, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5199, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0060, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5283, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0113, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5308, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0161, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5330, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0206, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5372, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0244, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5420, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0281, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5418, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0310, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5452, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0341, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5480, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0373, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5511, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0398, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5528, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0420, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5567, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0443, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5576, dtype=torch.float64, grad_fn=<NegBackward>)\n",
            "New best Discriminator cost: tensor(0.0465, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
            "New best Generator cost: tensor(-0.5593, dtype=torch.float64, grad_fn=<NegBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL0mp3QF7_ca"
      },
      "source": [
        "def generate_notes(model, network_input, int_to_note, n_notes):\n",
        "        \"\"\"Generate notes from the neural network based on a sequence of notes\"\"\"\n",
        "        # pick a random sequence from the input as a starting point for the prediction\n",
        "        with torch.no_grad():\n",
        "            start = np.random.randint(0, len(network_input) - n_notes)\n",
        "\n",
        "            # pattern = network_input[start]\n",
        "            prediction_output = []\n",
        "\n",
        "            # generate n_notes\n",
        "            for i in range(start, start + n_notes):\n",
        "                input_ = network_input[i]\n",
        "                ct_list = model(shuffle_music(input_))\n",
        "\n",
        "                for prediction in ct_list:\n",
        "                  index = prediction.argmax() * midi.input_norms[i]\n",
        "                  result = int_to_note[int(index)]\n",
        "                  prediction_output.append(result)\n",
        "\n",
        "\n",
        "            return prediction_output"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEqA6ewB-qh7"
      },
      "source": [
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def final_music_generator(inputs, note_weights):\n",
        "  music_generator_circuit(inputs, note_weights)\n",
        "  return measurement(n_note_encoding)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhnWOuio8JBk"
      },
      "source": [
        "generator_only = qml.QNode(final_music_generator, dev, interface=\"torch\")\n",
        "weight_gens = {\n",
        "    \"note_weights\": (n_gen_layers, n_note_encoding),\n",
        "}\n",
        "generator_only_layer = qml.qnn.TorchLayer(generator_only, weight_gens).to(running_dev)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucnsxtJS3T__",
        "outputId": "7ac28c9a-fabb-44d2-b38c-8153dc8d0faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "n_notes = 50\n",
        "generated_notes = []\n",
        "print(\"Generating notes\")\n",
        "notes = generate_notes(generator_only_layer, midi.network_input, midi.int_to_note, n_notes=n_notes)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating notes\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "QuantumFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mQuantumFunctionError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-3fb3f4bddf36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerated_notes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating notes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnotes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_only_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_to_note\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_notes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_notes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-341c88051f26>\u001b[0m in \u001b[0;36mgenerate_notes\u001b[0;34m(model, network_input, int_to_note, n_notes)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_notes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mct_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_music\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mct_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnn/torch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;31m# If the input is 1-dimensional, calculate the forward pass as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnn/torch.py\u001b[0m in \u001b[0;36m_evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         }\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutable\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqtape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;31m# construct the tape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;31m# If the observable contains a Hamiltonian and the device does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pennylane/qnode.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeasurementProcess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeasurement_processes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             raise qml.QuantumFunctionError(\n\u001b[0;32m--> 588\u001b[0;31m                 \u001b[0;34m\"A quantum function must return either a single measurement, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0;34m\"or a nonempty sequence of measurements.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m             )\n",
            "\u001b[0;31mQuantumFunctionError\u001b[0m: A quantum function must return either a single measurement, or a nonempty sequence of measurements."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edu8KMc3-JKk"
      },
      "source": [
        "model_name = f\"quGan{n_layers}-seq{seq_length}-cut{cutoff}-epcs{n_epochs}-qu{n_qubits}-nq{n_qlayers}\"\n",
        "model_str = f\"{model_name}.pt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rABcRRUG-LiU"
      },
      "source": [
        "print(\"Saving as MIDI file.\")\n",
        "midi.create_midi_from_model(notes, f\"{model_name}_generated.mid\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}